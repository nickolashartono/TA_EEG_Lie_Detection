{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8xdWZD_0P2_"
   },
   "source": [
    "# **INIT (RUN FIRST)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uN5Rgw_ZKYIU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from brainflow.board_shim import BoardShim, BrainFlowInputParams, LogLevels, BoardIds\n",
    "from brainflow.data_filter import DataFilter, FilterTypes\n",
    "import matplotlib\n",
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b_merIWfOLa1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mnickhartono\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "api_key = 'a45abb01f9556b57620ce77c8984452bee7a8772'\n",
    "board_id = 38\n",
    "# eeg_names = ['TP9', 'Fp1', 'Fp2', 'TP10', 'AUX']\n",
    "eeg_names = ['Fp1', 'Fp2']\n",
    "sf = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5AdfgRS8e4e"
   },
   "source": [
    "# **DATASET AND LOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g6lpQR06lzoq"
   },
   "outputs": [],
   "source": [
    "#INI DARI GAMBAR SPECTROGRAM\n",
    "class AutoencoderSpectrogramImage(Dataset):\n",
    "    def __init__(self, annotations_file, dir, transform=None):\n",
    "        self.file_lists = pd.read_csv(annotations_file, header=None)\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        # self.eeg_names = ['TP9', 'Fp1', 'Fp2', 'TP10', '_AUX']\n",
    "        self.eeg_names = ['Fp1', 'Fp2']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_lists)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.dir, self.file_lists.iloc[idx, 0].replace('/','\\\\'))\n",
    "        file_path = file_path[:-4] + '\\\\'\n",
    "        \n",
    "        spectrograms = []\n",
    "        for i in self.eeg_names:\n",
    "          temp = cv2.imread(file_path + i + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "          spectrograms.append(temp)\n",
    "        spectrograms = np.array(spectrograms)\n",
    "\n",
    "        if self.transform:\n",
    "            spectrograms = self.transform(spectrograms)\n",
    "            spectrograms = spectrograms.permute(1,2,0)\n",
    "        return spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-oTpov4r04NM"
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'D:\\\\Nicko\\\\TUGAS_AKHIR\\\\Dataset\\\\Dataset_TA\\\\'\n",
    "spectrogram_dir = 'D:\\\\Nicko\\\\TUGAS_AKHIR\\\\Dataset\\\\Dataset_TA_img\\\\'\n",
    "training_file = dataset_dir + 'training_dir.csv'\n",
    "testing_file = dataset_dir + 'testing_dir.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9Vv9M16UR0iG"
   },
   "outputs": [],
   "source": [
    "#buat image\n",
    "datasetTrain = AutoencoderSpectrogramImage(\n",
    "    annotations_file=training_file,\n",
    "    dir=spectrogram_dir,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "datasetTest = AutoencoderSpectrogramImage(\n",
    "    annotations_file=testing_file,\n",
    "    dir=spectrogram_dir,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2BfQcfNTja4x"
   },
   "outputs": [],
   "source": [
    "test = datasetTrain[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 180, 836])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NQqzUux6jH6q"
   },
   "outputs": [],
   "source": [
    "# split train to train and validation\n",
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(datasetTrain) * 0.8)\n",
    "valid_set_size = len(datasetTrain) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = torch.utils.data.random_split(datasetTrain, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "# data loader\n",
    "train_dataloader = DataLoader(train_set, batch_size=25, shuffle=True)\n",
    "validation_dataloader = DataLoader(valid_set, batch_size=25)\n",
    "test_dataloader = DataLoader(datasetTest, batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pCUjauSKoL9"
   },
   "source": [
    "# **AUTOENCODER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pgKFrU3YKr41"
   },
   "outputs": [],
   "source": [
    "#MODEL 1, 73216 param (32 x 22 x 104)\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 8, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            torch.nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(8, 5, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      embedding = self.encoder(x)\n",
    "      return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss, logger=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x = val_batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, logger=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ja518W8CX1jn"
   },
   "outputs": [],
   "source": [
    "encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 8, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 64, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(64, 64, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True)\n",
    "        )\n",
    "decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=2,\n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1,\n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2,\n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            # torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ConvTranspose2d(16, 8, 3, stride=2,\n",
    "            padding=1, output_padding=1),\n",
    "            # torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(8, 5, 3, stride=2,\n",
    "            padding=1, output_padding=1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ruQYK8vYxgp",
    "outputId": "0db46fa5-aac9-4b85-91e0-210302fc2b5a"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 5, 3, 3], expected input[1, 2, 180, 836] to have 5 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m result\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Given groups=1, weight of size [8, 5, 3, 3], expected input[1, 2, 180, 836] to have 5 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "result = encoder(test)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YrMNxPoahYr",
    "outputId": "33143150-50fe-4ca8-eaa5-dd616bec3ca3"
   },
   "outputs": [],
   "source": [
    "decoded = decoder(result)\n",
    "decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bh_kfaJWWCSf"
   },
   "outputs": [],
   "source": [
    "#MODEL 2, 9024 param (32 x 6 x 47)\n",
    "class LitAutoEncoder2(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 8, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(8, 5, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      embedding = self.encoder(x)\n",
    "      return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss, logger=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x = val_batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, logger=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zVAwW5khnha"
   },
   "outputs": [],
   "source": [
    "#MODEL 3, 12544 param (32 x 8 x 49)\n",
    "class LitAutoEncoder3(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 8, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2, \n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(8, 5, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      embedding = self.encoder(x)\n",
    "      return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss, logger=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x = val_batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, logger=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#MODEL 4, 16320 param (32 x 10 x 51)\n",
    "class LitAutoEncoder4(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 8, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(True),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=2,\n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 32, 3, stride=1,\n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2,\n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ConvTranspose2d(16, 8, 3, stride=2,\n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(8, 5, 3, stride=2,\n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      embedding = self.encoder(x)\n",
    "      return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss, logger=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x = val_batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, logger=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#MODEL 5, 32640 param (64 x 10 x 51)\n",
    "class LitAutoEncoder5(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(2, 8, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(32, 64, 3, stride=1, padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(32640, 16320),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(16320, 8160),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(8160, 4080)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4080, 8160),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(8160, 16320),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(16320, 32640),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Unflatten(1, torch.Size([64,10,51])),\n",
    "            torch.nn.ConvTranspose2d(64, 64, 3, stride=2,\n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(64, 32, 3, stride=1,\n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2,\n",
    "            padding=0, output_padding=0),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ConvTranspose2d(16, 8, 3, stride=2,\n",
    "            padding=1, output_padding=1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(8, 2, 3, stride=2,\n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      embedding = self.encoder(x)\n",
    "      return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss, logger=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x = val_batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, logger=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = torch.nn.functional.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3OHZ8uVTHO0",
    "outputId": "60b0d5b8-c73b-4d51-cffc-e75f78b76707"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LitAutoEncoder5(\n  (encoder): Sequential(\n    (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (12): Flatten(start_dim=1, end_dim=-1)\n    (13): ReLU(inplace=True)\n    (14): Linear(in_features=32640, out_features=16320, bias=True)\n    (15): ReLU(inplace=True)\n    (16): Linear(in_features=16320, out_features=8160, bias=True)\n    (17): ReLU(inplace=True)\n    (18): Linear(in_features=8160, out_features=4080, bias=True)\n  )\n  (decoder): Sequential(\n    (0): Linear(in_features=4080, out_features=8160, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Linear(in_features=8160, out_features=16320, bias=True)\n    (3): ReLU(inplace=True)\n    (4): Linear(in_features=16320, out_features=32640, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Unflatten(dim=1, unflattened_size=torch.Size([64, 10, 51]))\n    (7): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n    (13): ReLU(inplace=True)\n    (14): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (15): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (16): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): ConvTranspose2d(8, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n  )\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = LitAutoEncoder5()\n",
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666668335, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fa9f4a8b11542caad802a52c8db4892"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\Nicko\\TUGAS_AKHIR\\AutoEncoder\\model_5\\wandb\\run-20230427_140911-iicx92ip</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/nickhartono/autoencoder/runs/iicx92ip' target=\"_blank\">genial-puddle-30</a></strong> to <a href='https://wandb.ai/nickhartono/autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/nickhartono/autoencoder' target=\"_blank\">https://wandb.ai/nickhartono/autoencoder</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/nickhartono/autoencoder/runs/iicx92ip' target=\"_blank\">https://wandb.ai/nickhartono/autoencoder/runs/iicx92ip</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project='autoencoder', save_dir='D:\\\\Nicko\\\\TUGAS_AKHIR\\\\AutoEncoder\\\\model_5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "ZbHhCzmnQIip",
    "outputId": "37ac323c-8721-4e1a-be27-85ab4cebfbb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 699 M \n",
      "1 | decoder | Sequential | 699 M \n",
      "---------------------------------------\n",
      "1.4 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 B     Total params\n",
      "5,594.025 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77a03fdc3f4c4b3a9cbc0814a1f20506"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "D:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c5255a1a06d4689bff0184815074666"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.99 GiB (GPU 0; 8.00 GiB total capacity; 5.37 GiB already allocated; 644.12 MiB free; 5.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3000\u001B[39m, devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m'\u001B[39m, log_every_n_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m9\u001B[39m, logger\u001B[38;5;241m=\u001B[39mwandb_logger)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    606\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_unwrap_optimized(model)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[1;32m--> 608\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 38\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     41\u001B[0m     trainer\u001B[38;5;241m.\u001B[39m_call_teardown_hook()\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    643\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[0;32m    644\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_set_ckpt_path(\n\u001B[0;32m    645\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    646\u001B[0m     ckpt_path,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    647\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    648\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    649\u001B[0m )\n\u001B[1;32m--> 650\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mrestore_training_state()\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[1;32m-> 1112\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1114\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1115\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_teardown()\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m   1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[1;32m-> 1191\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1214\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1211\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m   1213\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[1;32m-> 1214\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:267\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher\u001B[38;5;241m.\u001B[39msetup(dataloader, batch_to_device\u001B[38;5;241m=\u001B[39mbatch_to_device)\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 267\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:213\u001B[0m, in \u001B[0;36mTrainingEpochLoop.advance\u001B[1;34m(self, data_fetcher)\u001B[0m\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_started()\n\u001B[0;32m    212\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 213\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[0;32m    217\u001B[0m \u001B[38;5;66;03m# update non-plateau LR schedulers\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\batch\\training_batch_loop.py:88\u001B[0m, in \u001B[0;36mTrainingBatchLoop.advance\u001B[1;34m(self, kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mautomatic_optimization:\n\u001B[0;32m     85\u001B[0m     optimizers \u001B[38;5;241m=\u001B[39m _get_active_optimizers(\n\u001B[0;32m     86\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39moptimizers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39moptimizer_frequencies, kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     87\u001B[0m     )\n\u001B[1;32m---> 88\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     90\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmanual_loop\u001B[38;5;241m.\u001B[39mrun(kwargs)\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:202\u001B[0m, in \u001B[0;36mOptimizerLoop.advance\u001B[1;34m(self, optimizers, kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madvance\u001B[39m(\u001B[38;5;28mself\u001B[39m, optimizers: List[Tuple[\u001B[38;5;28mint\u001B[39m, Optimizer]], kwargs: OrderedDict) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    200\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_kwargs(kwargs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hiddens)\n\u001B[1;32m--> 202\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_optimization\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim_progress\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_position\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    204\u001B[0m         \u001B[38;5;66;03m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001B[39;00m\n\u001B[0;32m    205\u001B[0m         \u001B[38;5;66;03m# would be skipped otherwise\u001B[39;00m\n\u001B[0;32m    206\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_idx] \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39masdict()\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:249\u001B[0m, in \u001B[0;36mOptimizerLoop._run_optimization\u001B[1;34m(self, kwargs, optimizer)\u001B[0m\n\u001B[0;32m    241\u001B[0m         closure()\n\u001B[0;32m    243\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;66;03m# the `batch_idx` is optional with inter-batch parallelism\u001B[39;00m\n\u001B[1;32m--> 249\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch_idx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m result \u001B[38;5;241m=\u001B[39m closure\u001B[38;5;241m.\u001B[39mconsume_result()\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;66;03m# if no result, user decided to skip optimization\u001B[39;00m\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;66;03m# otherwise update running loss + reset accumulated loss\u001B[39;00m\n\u001B[0;32m    256\u001B[0m     \u001B[38;5;66;03m# TODO: find proper way to handle updating running loss\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:370\u001B[0m, in \u001B[0;36mOptimizerLoop._optimizer_step\u001B[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001B[0m\n\u001B[0;32m    362\u001B[0m     rank_zero_deprecation(\n\u001B[0;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    367\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m return True.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    368\u001B[0m     )\n\u001B[0;32m    369\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124musing_native_amp\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprecision_plugin, MixedPrecisionPlugin)\n\u001B[1;32m--> 370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_call_lightning_module_hook(\n\u001B[0;32m    371\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer_step\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mcurrent_epoch,\n\u001B[0;32m    373\u001B[0m     batch_idx,\n\u001B[0;32m    374\u001B[0m     optimizer,\n\u001B[0;32m    375\u001B[0m     opt_idx,\n\u001B[0;32m    376\u001B[0m     train_step_and_backward_closure,\n\u001B[0;32m    377\u001B[0m     on_tpu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39maccelerator, TPUAccelerator),\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    379\u001B[0m     using_lbfgs\u001B[38;5;241m=\u001B[39mis_lbfgs,\n\u001B[0;32m    380\u001B[0m )\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_accumulate:\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_completed()\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1356\u001B[0m, in \u001B[0;36mTrainer._call_lightning_module_hook\u001B[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1353\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[0;32m   1355\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1356\u001B[0m     output \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[0;32m   1359\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1742\u001B[0m, in \u001B[0;36mLightningModule.optimizer_step\u001B[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_lbfgs)\u001B[0m\n\u001B[0;32m   1663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimizer_step\u001B[39m(\n\u001B[0;32m   1664\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1665\u001B[0m     epoch: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1671\u001B[0m     using_lbfgs: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1672\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1673\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1674\u001B[0m \u001B[38;5;124;03m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001B[39;00m\n\u001B[0;32m   1675\u001B[0m \u001B[38;5;124;03m    each optimizer.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1740\u001B[0m \n\u001B[0;32m   1741\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1742\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_closure\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:169\u001B[0m, in \u001B[0;36mLightningOptimizer.step\u001B[1;34m(self, closure, **kwargs)\u001B[0m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 169\u001B[0m step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy\u001B[38;5;241m.\u001B[39moptimizer_step(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_idx, closure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_after_step()\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:234\u001B[0m, in \u001B[0;36mStrategy.optimizer_step\u001B[1;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001B[39;00m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, pl\u001B[38;5;241m.\u001B[39mLightningModule)\n\u001B[1;32m--> 234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39moptimizer_step(\n\u001B[0;32m    235\u001B[0m     optimizer, model\u001B[38;5;241m=\u001B[39mmodel, optimizer_idx\u001B[38;5;241m=\u001B[39mopt_idx, closure\u001B[38;5;241m=\u001B[39mclosure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    236\u001B[0m )\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:119\u001B[0m, in \u001B[0;36mPrecisionPlugin.optimizer_step\u001B[1;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001B[39;00m\n\u001B[0;32m    118\u001B[0m closure \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001B[1;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m optimizer\u001B[38;5;241m.\u001B[39mstep(closure\u001B[38;5;241m=\u001B[39mclosure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m--> 140\u001B[0m     out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 23\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\optim\\adam.py:183\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure, grad_scaler)\u001B[0m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[1;32m--> 183\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[0;32m    186\u001B[0m     params_with_grad \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:105\u001B[0m, in \u001B[0;36mPrecisionPlugin._wrap_closure\u001B[1;34m(self, model, optimizer, optimizer_idx, closure)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_closure\u001B[39m(\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     94\u001B[0m     model: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.LightningModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     97\u001B[0m     closure: Callable[[], Any],\n\u001B[0;32m     98\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001B[39;00m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \n\u001B[0;32m    102\u001B[0m \u001B[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 105\u001B[0m     closure_result \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_after_closure(model, optimizer, optimizer_idx)\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m closure_result\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:149\u001B[0m, in \u001B[0;36mClosure.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Tensor]:\n\u001B[1;32m--> 149\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclosure(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\u001B[38;5;241m.\u001B[39mloss\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:144\u001B[0m, in \u001B[0;36mClosure.closure\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_zero_grad_fn()\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m step_output\u001B[38;5;241m.\u001B[39mclosure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 144\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:305\u001B[0m, in \u001B[0;36mOptimizerLoop._make_backward_fn.<locals>.backward_fn\u001B[1;34m(loss)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward_fn\u001B[39m(loss: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbackward\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_idx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1494\u001B[0m, in \u001B[0;36mTrainer._call_strategy_hook\u001B[1;34m(self, hook_name, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1491\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1494\u001B[0m     output \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:207\u001B[0m, in \u001B[0;36mStrategy.backward\u001B[1;34m(self, closure_loss, optimizer, optimizer_idx, *args, **kwargs)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    205\u001B[0m closure_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpre_backward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module)\n\u001B[1;32m--> 207\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mbackward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, optimizer, optimizer_idx, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    209\u001B[0m closure_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpost_backward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module)\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_backward(closure_loss)\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:67\u001B[0m, in \u001B[0;36mPrecisionPlugin.backward\u001B[1;34m(self, tensor, model, optimizer, optimizer_idx, *args, **kwargs)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     49\u001B[0m     tensor: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m     55\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m        \\**kwargs: Keyword arguments for the same purpose as ``*args``.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 67\u001B[0m     model\u001B[38;5;241m.\u001B[39mbackward(tensor, optimizer, optimizer_idx, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1486\u001B[0m, in \u001B[0;36mLightningModule.backward\u001B[1;34m(self, loss, optimizer, optimizer_idx, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fabric\u001B[38;5;241m.\u001B[39mbackward(loss, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    487\u001B[0m     )\n\u001B[1;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Nicko\\TUGAS_AKHIR\\TA_env\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 1.99 GiB (GPU 0; 8.00 GiB total capacity; 5.37 GiB already allocated; 644.12 MiB free; 5.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=3000, devices=1, accelerator='gpu', log_every_n_steps=9, logger=wandb_logger)\n",
    "trainer.fit(autoencoder, train_dataloader, validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "eced4943117947f0a8b77095015c8d1b",
      "ded5751f20f1483699749718d3fad109",
      "ee4c99c9299948fcab2bb994dcf62b05",
      "79c872b27c334d14bf769916ecb41a70",
      "f4f4915d880f49dab7b08a346525d475",
      "e1c7909b88d04294aae81d060fa386f7",
      "490e37c706314bb69584749dc0f0d51a",
      "589965d92ec34bd1be3dcdb0fdd166e1",
      "756a8a66c62143c196c2eb8e9ebe3017",
      "863eeb87ee6540428202f55ec1731d7a",
      "161a543813a2426f92e44ec088d41791"
     ]
    },
    "id": "RBLiqTqDv5_L",
    "outputId": "7e74e400-bf85-4392-8001-5cfd87247506"
   },
   "outputs": [],
   "source": [
    "trainer.test(autoencoder, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrUIlO2KRzBi"
   },
   "outputs": [],
   "source": [
    "data_test = datasetTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYYImaKMRzBj"
   },
   "outputs": [],
   "source": [
    "data_test = data_test[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "_--EERDmRzBj",
    "outputId": "2797c012-5a9d-4b17-bc03-2670aa7a62d3"
   },
   "outputs": [],
   "source": [
    "data_squeezed = torch.squeeze(data_test)\n",
    "plt.imshow(data_squeezed[1].numpy()*255, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujmqz4i_RzBj",
    "outputId": "c57e0ba7-f9a9-44b5-9241-d191f1a21f8d"
   },
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "result = autoencoder(data_test)\n",
    "decoded_result = autoencoder.decoder(result)\n",
    "decoded_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "dtzzJ8oFRzBk",
    "outputId": "6e6bbf72-06f2-40f4-808d-cd920add9538"
   },
   "outputs": [],
   "source": [
    "decoded_squeezed = torch.squeeze(decoded_result)\n",
    "plt.imshow(decoded_squeezed[1].detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder = autoencoder.load_from_checkpoint('D:\\\\Nicko\\\\TUGAS_AKHIR\\\\AutoEncoder\\\\model_4\\\\epoch=2999-step=27000.ckpt')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "a8xdWZD_0P2_",
    "w5AdfgRS8e4e"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "eced4943117947f0a8b77095015c8d1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ded5751f20f1483699749718d3fad109",
       "IPY_MODEL_ee4c99c9299948fcab2bb994dcf62b05",
       "IPY_MODEL_79c872b27c334d14bf769916ecb41a70"
      ],
      "layout": "IPY_MODEL_f4f4915d880f49dab7b08a346525d475"
     }
    },
    "ded5751f20f1483699749718d3fad109": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1c7909b88d04294aae81d060fa386f7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_490e37c706314bb69584749dc0f0d51a",
      "value": "Testing DataLoader 0: 100%"
     }
    },
    "ee4c99c9299948fcab2bb994dcf62b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_589965d92ec34bd1be3dcdb0fdd166e1",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_756a8a66c62143c196c2eb8e9ebe3017",
      "value": 3
     }
    },
    "79c872b27c334d14bf769916ecb41a70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_863eeb87ee6540428202f55ec1731d7a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_161a543813a2426f92e44ec088d41791",
      "value": " 3/3 [00:05&lt;00:00,  1.94s/it]"
     }
    },
    "f4f4915d880f49dab7b08a346525d475": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e1c7909b88d04294aae81d060fa386f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "490e37c706314bb69584749dc0f0d51a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "589965d92ec34bd1be3dcdb0fdd166e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "756a8a66c62143c196c2eb8e9ebe3017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "863eeb87ee6540428202f55ec1731d7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "161a543813a2426f92e44ec088d41791": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
